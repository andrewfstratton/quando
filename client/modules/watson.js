(() => {
  let quando = this['quando']
  if (!quando) {
      alert('Fatal Error: Watson must be included after quando_browser')
  }
  let self = quando.watson = {}
  let mediaRecorder = null
  let recording = false

  self.call_tts = function(text, val) {        
    if (typeof val === 'string' && val.length) {
      text = val
    }
    //send POST request to server
    fetch('/watson/TTS_request', { method: 'POST', 
        body: JSON.stringify({'text':text}), 
        headers: {"Content-Type": "application/json",
                  Accept: 'application/json'}
    }).then(function(response) {
      response.json().then(function(data) {
        console.log(data)
        //play audio after 
        window.setTimeout(()=> {
          quando.audio(data+'.wav', false)
        }, 0)
      })
    })
  } 
    
  // self.call_ass = function(text) {
  //   //send POST request to server
  //   fetch('/watson/ASS_request', { method: 'POST', 
  //       body: JSON.stringify({'text':text}), 
  //       headers: {"Content-Type": "application/json",
  //                 Accept: 'application/json'}
  //   }).then(function(response) {
  //     console.log(response)
  //     let output = JSON.parse(response)
  //     quando.text(output.generic[0].text, true)
  //   })
  // } 

  self.call_vis_rec = function(goalClass, fn) {
    goalClass = goalClass.toLowerCase()
    quando.ar.getScene() // forces scene creation
    const canvas = document.getElementById('hiddenCanvas')
    const context = canvas.getContext('2d')
    //placeholder variables
    let vid = null
    let imgData = null

    //timeout of 3 seconds to wait for webcam feed to load in
    window.setTimeout(()=>{
      let div = document.getElementById('visrec_label')
      let elem = document.getElementById('quando_labels')

      //if label doesn't already exist, create label
      if (div == null) {
        div = document.createElement('div')
        div.className = 'quando_label'
        div.innerHTML = "ðŸ“·"
        div.setAttribute('id', 'visrec_label')
      }

      /*Get all video elements, then find the one that's
      direct parent is the body, which must be the webcam
      feed generated by AR.js*/
      var videos = document.getElementsByTagName('video')
      for (i=0; i<videos.length; i++){
        if (videos[i].parentNode == body) {
          vid = videos[i]
        }
      }
      if (vid == null) {
        alert('Webcam feed not available!')
      }

      div.addEventListener("click", function(){
        //save snapshot of webcam feed as dataURL
        context.drawImage(vid, 0, 0, 250, 200)
        imgData = canvas.toDataURL("image/png")
        //call api using this snapshot as input
        div.innerHTML = "Working..."
        self.call_vis_rec_api(imgData, goalClass, fn)
      })
      elem.appendChild(div)
    }, 3000)
  }

  self.call_vis_rec_api = function(imgData, goalClass, fn) {
        //send POST request to server
        fetch('/watson/VISREC_request', { method: 'POST', 
        body: JSON.stringify({'imgData':imgData}), 
        headers: {"Content-Type": "application/json"}
      }).then(
  
        //once POST request is done
        function(response) {

          let div = document.getElementById('visrec_label')
          div.innerHTML = "Click to try again..."

          response.json().then(function(data) {
            //has it seen what it wants to?
            if (data.includes(goalClass)) {
              //execute box
              fn()
            } else (
              quando.text(data)
            )
          })
        }
      )
  }
  
  self.call_speech_to_text = function() {  
    quando.promptInput()
    let div = document.getElementById('visrec_label')
    let elem = document.getElementById('quando_labels')
    //if label doesn't already exist, create label
    if (div == null) {
      div = document.createElement('div')
      div.className = 'quando_label'
      div.innerHTML = "Click to start listening..."
      div.setAttribute('id', 'stt_label')
    }
    navigator.mediaDevices.getUserMedia({ audio: true, video: false }).then(stream => {
      mediaRecorder = new MediaRecorder(stream, { mimeType: "audio/webm" })
      mediaRecorder.ondataavailable = e => {
        if (mediaRecorder.state == "inactive") {
          const audioBlob = new Blob([e.data],{type:"audio/webm"});
          var reader = new window.FileReader();
          reader.readAsDataURL(audioBlob);
          reader.onloadend = function() {
             base64 = reader.result;
             base64 = base64.split(',')[1];
             fetch('/watson/SPEECH_request', { method: 'POST', 
               body: JSON.stringify({'data':base64}), 
               headers: {"Content-Type": "application/json"}
             }).then((response) => {
                response.json().then((data) => {
                  div.innerHTML = "Click to start listening..."
                  if (!data.error) {
                    const text = data.replace(/"/g, "")
                    console.log(text)

                    let input = document.getElementById('inp')
                    if (input) {
                      input.value = text
                      input.click()
                    }
                  }
                })
              })
          }
        }
      }
    })
    div.addEventListener("click", () => {
      if (!recording) {
        mediaRecorder.start()
        div.innerHTML = "Stop listening..."
        recording = true
      } else {
        quando.message.send('rec stop')
        recording = false
        mediaRecorder.stop()
        div.innerHTML = "Working..."
      }
    }) 
    elem.appendChild(div)
    /*/send POST request to server*/
  }

  self.startRec = () => {
    mediaRecorder.start()
    recording = true
  }

  self.stopRec = () => {
    recording = false
    mediaRecorder.stop()
  }

  self.addToneHandler = function(goalTone, fn) {
    //adds 'onClick' event listener to the input prompt button
    //which submits the prompts text to the tone analyzer
    let input = document.getElementById('inp')
    let button = document.getElementById('inpButton')

    button.addEventListener("click", function(){
      //send POST request to server
      fetch('/watson/TONE_request', { method: 'POST', 
        body: JSON.stringify({'text':input.value}), 
        headers: {"Content-Type": "application/json"}
      }).then(function(response) {
        response.json().then(function(data) {
          //if tone of input is goal
          if (data.includes(goalTone)) {
            //execute box
            fn()
          }
        })
      })
    })
  }

})()
